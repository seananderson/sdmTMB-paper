---
title: "sdmTMB: Fast, flexible, and user-friendly spatial and spatiotemporal generalized linear mixed-effects models"
author: "|
  Sean C. Anderson$^1$^[Corresponding author: sean.anderson@dfo-mpo.gc.ca], Other authors\n| $^1$Pacific Biological Station Fisheries and Oceans Canada, \n| Nanaimo, BC, Canada\n|
  $^2$Other addresses\n"
output:
    bookdown::pdf_document2:
      toc: false
      number_sections: false
      fig_caption: true
      highlight: "monochrome"
csl: mee.csl
bibliography: refs.bib
link-citations: yes
header-includes:
  \usepackage{setspace}\onehalfspacing
  \usepackage[left]{lineno}
  \usepackage{bm}
  \usepackage{amssymb}
  \usepackage{tablefootnote}
  \linenumbers
  \newcommand{\beginsupplement}{
  \setcounter{equation}{0}
  \renewcommand{\theequation}{S.\arabic{equation}}
  \setcounter{table}{0}
  \renewcommand{\thetable}{S\arabic{table}}
  \setcounter{figure}{0}
  \renewcommand{\thefigure}{S\arabic{figure}}}
editor_options:
  markdown:
    wrap: sentence
abstract: |
    | \noindent Point 1: set the context for and purpose of the work;
    | Point 2: indicate the approach and methods;
    | Point 3: outline the main results;
    | Point 4: identify the conclusions and the wider implications.
---

```{r, echo = FALSE, include = FALSE, message = FALSE, warning = FALSE}
library(here)
library(ggplot2)
theme_set(theme_minimal())
# theme_set(ggsidekick::theme_sleek())
library(dplyr)
library(sdmTMB)
```

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

<!-- TODO: cite:  -->
<!-- @article{gelfand2017, -->
<!--   title = {Bayesian Modeling and Analysis of Geostatistical Data}, -->
<!--   author = {Gelfand, Alan E. and Banerjee, Sudipto}, -->
<!--   year = {2017}, -->
<!--   journal = {Annual Review of Statistics and Its Application}, -->
<!--   volume = {4}, -->
<!--   number = {1}, -->
<!--   pages = {245--266}, -->
<!--   doi = {10.1146/annurev-statistics-060116-054155}, -->
<!--   annotation = {\_eprint: https://doi.org/10.1146/annurev-statistics-060116-054155} -->

<!-- @book{diggle2007, -->
<!--   title = {Model-Based {{Geostatistics}}}, -->
<!--   author = {Diggle, Peter and Ribeiro, Paulo Justiniano}, -->
<!--   year = {2007}, -->
<!--   publisher = {{Springer}}, -->
<!--   googlebooks = {qCqOm39OuFUC}, -->
<!--   isbn = {978-0-387-48536-2}, -->
<!--   langid = {english} -->
<!-- } -->

<!-- } -->

Ecological data are often collected in space or in space repeatedly over time.
While such data are a rich source of information about ecological processes [@legendre1989a], they are challenging to properly model---data closer in space and time are usually more similar to each other than data farther apart, both due to measured and unmeasured variables [@cressie1993; @cressie2011].
While measured variables can be accounted for via predictors in a model (e.g., measuring and modelling temperature effects on species abundance), unmeasured variables (e.g., everything influencing species abundance but not explicitly modelled) can cause residual spatial correlation.
This residual correlation is ideally dealt with because doing so (1) allows for valid statistical inference [@legendre1989a], (2) can improve predictions compared to ignoring it [e.g., @shelton2014], and (3) can be of ecological interest itself [e.g., @thorson2019d, @barnett2021].

Geostatistical GLMMs (generalized linear mixed effects models) with spatially correlated random effects are a class of models appropriate for these data.
Similarly to how random intercepts can account for correlation among groups (e.g., plants counted in plots of land), spatial or spatiotemporal random effects can account for unmeasured variables causing observations to be correlated in space or space and time.
A common approach to modelling these spatial effects is with Gaussian random fields (GRFs), where the random effects describing the spatial patterning are assumed drawn from a multivariate normal (MVN) distribution, constrained by some covariance function such as the exponential or Matérn [@cressie1993; @diggle1998; @chiles1999].

While simple on the surface, such models quickly become computationally limiting due to the need to invert large matrices to keep track of covariation among data [e.g., @latimer2009].
Many solutions have been proposed, such as predictive processes [@banerjee2008; @latimer2009], the stochastic partial differential equation (SPDE) approximation to Gaussian Markov random fields (GMRFs) [@lindgren2011], and nearest-neighbour Gaussian processes [@datta2016].
These approaches reduce the scale of the covariance estimation problem while providing a means to evaluate the data likelihood, thereby allowing fitting via Bayesian or maximum likelihood methods.
This can make an enormous difference to computational efficiency [@heaton2017].
The SPDE approach is a solution popularized via the INLA R package [@rue2009; @lindgren2011] and an implementation in TMB [Template Model Builder, @kristensen2016] that partially relies on INLA to create input matrices [e.g., @osgood-zimmerman2021].
Details are beyond the scope of this paper, and are not necessary to use the software discussed here, but the idea is that the solution to a specific SPDE is a GRF with a Matérn covariance function and this 'trick' enables one to efficiently fit GRFs to large spatial datasets [@lindgren2011].

Systems for specifying statistical models that can include the SPDE, such as INLA and TMB, are flexible and powerful but are challenging to use for many applied ecologists.
For example, TMB requires the user to program in a C++ template and it can be slow to experiment with multiple models when writing bespoke model code.
Packages such as lme4 [@bates2015] and glmmTMB [@brooks2017] let users quickly iterate and explore statistical models---focusing on evaluating fit and comparing models---but do not have built-in SPDE functionality.
Packages such as VAST [@thorson2019] and inlabru [@bachl2019] are powerful user interfaces to spatial models that use the SPDE, but either lack a modular interface familiar to those who have used lme4 or glmmTMB, or lack some of the flexibility for the particular class of models discussed here.
We provide a more detailed comparison of related software packages in Table 1 and the Discussion.
<!-- User interfaces through software such as VAST or inlabru can greatly reduce these challenges. VAST is built on TMB, and is extremely powerful (e.g., fitting many multivariate models not described here), but does not provide a simple, familiar, modular interface for users with basic spatial or spatiotemporal data. inlabru provides a somewhat more familiar interface to a large class of models including GRMF models, but is strictly Bayesian, lacks some flexibility for the particular class of models discussed here. It also relies on INLA, and at least for some problems, TMB can be much faster [@osgood-zimmerman2021]. We provide a more detailed comparison of related software packages in Table 1 and the discussion. -->

<!-- User interfaces to classes of models fit by these template systems can greatly  -->

<!-- reduce these challenges for the vast majority of models. -->

<!-- keep the above even briefer? -->

<!-- inlabru is "very good" but not entirely familiar to those used to `glm()`, lme4, glmmTMB, or mgcv; -->

<!-- *TODO: the differences are many and more than can be listed here. Keep brief add Table or discussion later about differences and when to pick one over the other?* -->

Here, we introduce our R package sdmTMB, which implements geostatistical spatial and spatiotemporal GLMMs using TMB for model fitting and INLA to set up SPDE matrices.
Our aim is not to replace any of the above-mentioned statistical packages, but to provide a fast, flexible, and user-friendly interface for a specific class of spatial and spatiotemporal models that should be familiar to users of lme4, glmmTMB, or mgcv [@wood2017a].
One common application is for species distribution models (SDMs), hence the package name.
This paper describes the basic functionality of the R package and the underlying statistical model, illustrates its use through TODO case studies, and concludes with a discussion of related software.

<!-- -   [@anderson2019] -->
<!-- -   [@maureaud2021] -->
<!-- -   [@anderson2020] -->
<!-- -   [@osgood-zimmerman2021] -->
<!-- -   [@breivik2021] -->
<!-- -   [@monnahan2021] -->
<!-- -   [@shelton2014] -->
<!-- -   [@lindgren2011] -->
<!-- -   [@latimer2009] -->

<!-- Packages: -->

<!-- spaMM: @rousset2014 -->
<!-- spNNGP: @finley2021 -->


<!-- millard1985: Space–Time Correlation and Its Effects on Methods for Detecting Aquatic Ecological Change "In practice, spatial correlation is more likely to be a problem than is temporal correlation, given typical monitoring frequencies." -->

<!-- legendre1989a: "Spatial pattern and ecological analysis": "We can expect the spatial approach to ecological problems to bring about a quantum jump for ecologists and population geneticists who had learned a type of statistics where one had to hide space or time structures. It is now possible to use these structures and to integrate them into our analyses as fully-fledged controlled variables." -->

<!-- ecology has a latitude gradient: von Humboldt, A. (1808) Ansichten der Natur mit wissenschaftlichen Erlauterungen. J.G. Cotta, Tübingen, Germany. -->

(ref:diagram-fig) Components of an sdmTMB model with illustrations, descriptions, examples, notation, and example code.
An sdmTMB model can be built from any combination of the process components (first six rows) plus an observation component (last row).
The examples are from an SDM context, but the model can be fit to any spatially referenced point data.
Notation:
We refer to design matrices as $\bm{X}$.
The indexes $\bm{s}$, $t$, and $g$ index spatial coordinates, time, and 'group', respectively.
The $\sigma$ and $\bm{\Sigma}$ symbols represent standard deviations and covariance matrices, respectively.
All other symbols refer to the  described model components.
Note that `s()` denotes a smoother as in mgcv [@wood2017a], `breakpt()` denotes a breakpoint 'hockey-stick' shape [e.g., @barrowman2000], `(1|g) ` denotes a random intercept by group `g`, and `~ 0` is used in an R formula to omit an intercept.

```{r diagram, fig.cap="(ref:diagram-fig)"}
f <- here::here("figs", "diagram.pdf")
if (!file.exists(f)) {
  download.file("https://www.dropbox.com/s/j8km3hv8xz9b63k/diagram.pdf?dl=1", 
    destfile = f)
}
knitr::include_graphics(f)
```

# Model description

sdmTMB fits GLMMs to spatial or spatiotemporal geostatistical data.
Geostatistical data simply refers to data observed at specific spatial coordinates (vs. areal data that might represent polygons or grids).
The data can be collected across discrete points in time.
The process component of an sdmTMB model can be formed by any combination of main ('fixed') effects, spatial random fields, spatiotemporal random fields, IID random intercepts, time-varying effects, and spatially varying effects (Fig. \@ref(fig:diagram)).
This process component is combined with an observation error family (e.g., Gaussian, Gamma, binomial, Tweedie) and link (e.g., identity, log, logit).

Using the notation of a bold capital letter to represent a data matrix or vector, a bold lowercase greek letter to represent a parameter vector, the index $\bm{s}$ to represent a point in space, and the index $t$ to represent a point in time,
the general form of a GLMM is
$g(\bm{\mu}) = \bm{X \beta} + \bm{Z \psi}$,
with the inverse link function $g(x)$ relating the mean $\bm{\mu}$ to fixed-effect predictors in the design matrix $\bm{X}$ with estimated coefficients $\bm{\beta}$ and random effects with the design matrix $\bm{Z}$ with estimated coefficients $\bm{\psi}$.
<!-- The matrix $\bm{Z}$ allows random effects to be structured (e.g., intercepts varying by group) or unstructured, with $\bm{u}$ representing random variation. -->
For clarity, we partition the random effects $\bm{Z \psi}$ into a number of more interpretable components, each of which can optionally be included in the model. 
Although in practice it is rare to include all of these components, the full sdmTMB model is
$$
g(\mu_{\bm{s},t}) =
\bm{X}_{1,\bm{s},t} \bm{\beta} +
\bm{\alpha}_g +
\bm{X}_{2,\bm{s},t} \gamma_t +
\bm{X}_{3,t} \zeta_{\bm{s}} +
\omega_{\bm{s}} +
\epsilon_{\bm{s},t},
$$
where

* $\bm{X}_{1,\bm{s},t}$, $\bm{X}_{2,\bm{s},t}$, and $\bm{X}_{3,\bm{s},t}$ represent design matrices;
* $\bm{\beta}$ represents a vector of fixed-effect coefficients;
* $\alpha_{g}$ represents random intercepts by group $g$, $\alpha_{g}\sim \mathrm{N}(0,\sigma^2_\alpha)$;
* $\gamma_{t}$ represents time-varying coefficients (a random walk), $\gamma_{t} \sim \mathrm{N}(\gamma_{t-1},\sigma^2_\gamma)$;
* $\zeta_{\bm{s}}$ represents spatially varying coefficients (a random field), $\zeta_{\bm{s}} \sim \mathrm{MVN}(\bm{0},\bm{\Sigma}_\zeta)$;
* $\omega_{\bm{s}}$ represents a random spatial component (a random field), $\omega_{\bm{s}} \sim \mathrm{MVN}(\bm{0},\bm{\Sigma}_\omega)$; and
* $\epsilon_{\bm{s},t}$ represents a spatiotemporal component (a random field), $\epsilon_{\bm{s},t} \sim \mathrm{MVN}(\bm{0},\bm{\Sigma}_{\epsilon})$.

sdmTMB models are spatially explicit models---they estimate interpretable parameters of a spatial covariance function: parameters defining the magnitude of spatial variation and the rate of correlation decay with distance.
In contrast, semi- and non-parametric approaches do not estimate spatial covariance functions (e.g., randomForest [@liaw2002], MaxEnt [@phillips2006], most smooths in mgcv [@wood2017a]).
The random fields in sdmTMB are structured as MVN constrained by a Matérn covariance function [@matern1960].
The Matérn can accommodate a range of shapes and can be both isotropic (covariance decays the same in all directions) or anisotropic (covariance in the latitudinal direction may differ from the longitudinal direction) (REF).
The Matérn standard deviations are estimated separately for the various fields and the range---the distance at which spatial correlation decays to $\sim$ 0.13 (REF)---can be shared or estimated separately.

<!-- - high-level paragraph or two about what the model includes, referencing Fig 1 -->
<!-- - high-level paragraph about design philosophy (modular [separate predict, residuals, etc.], familiar/clear naming, expensive computations only if needed, work with regular data frames, ...?) -->
<!-- - high-level paragraph about simulation capabilities and + testing performed (reference supplement) -->
<!-- - model selection/cross validation paragraph -->
<!-- - derived quantities paragraph (or just put this in the examples?) -->

<!-- - example 1 + figs -->
<!-- - example 2 + figs -->

<!--     - perhaps a paragraph on how it achieves what Jim outlined @thorson2019 as necessary: -->
<!--         -   "VAST represents four main design principles. Although there are many other implementation details that distinguish VAST from previous index-standardization methods, I believe that these four design principles represent the features that any future replacement should include." -->
<!--         -   Area weighting (check, helper functions to sum up weighted grid cells) -->
<!--         -   Distinct catchability and habitat covariates (check, decide what goes into `predict()`) -->
<!--         -   Condition on missing covariates (check, random fields) -->
<!--         -   Bridge between univariate and multivariate applications (no! should we? -->

<!-- sdmTMB in its current form achieves 3 of the 4 design principles outlined by @thorson2019 for index standardization:  -->


<!-- (e.g., 'catchability' and 'habitat' covariates in VAST merely depend on the values supplied to `predict()` in sdmTMB). -->

<!-- # Model -->

<!-- Although sdmTMB has been developed with spatial or spatiotemporal modelling as a primary focus, the statistical models it fits fall under the class of GLMMs. -->
<!-- GLMMs are available in several widely used packages, including glmmTMB [@brooks2017], mgcv [@wood2017a], and lme4 [@bates2015], and to allow comparison with these packages, sdmTMB allows for spatial and spatiotemporal effects to be omitted. -->

By default, if spatiotemporal fields are included, they are assumed independent and identically distributed (IID); however, additional options allow them to be modelled as a random walk or first-order autoregressive, AR(1), process (Fig.\ \@ref(fig:diagram)).
Turning off both spatial and spatiotemporal effects allows comparison with a standard non-spatial GLM or GLMM.
We include additional flexibility in specifying the linear fixed effect matrix: covariates can be modelled as penalized smooth functions (generalized additive models; GAMs) using the same `s()` syntax as in mgcv [@wood2017a], or to be modelled with threshold shapes [e.g., hockey stick models, `breakpt()`, @barrowman2000] or logistic functions, `logistic()`.

The sdmTMB model is fit by maximum marginal likelihood.
Internally, a TMB [@kristensen2016] model template calculates the marginal log likelihood and its gradient, and the negative log likelihood is minimized via the non-linear optimization routine `stats::nlminb()` in R [@gay1990; @r2021].
Random effects are estimated at values that maximize the log likelihood conditional on the estimated fixed effects and are integrated over via the Laplace approximation [@kristensen2016].

<!-- [paragraph about spde and gaussian process / Matern covariance here] -->

<!-- Paragraph on model selection here-->

## Model selection

Following glmmTMB, we allow AIC to be calculated for each sdmTMB model [`aic()`, @akaike1974]. 
Because of well-documented biases of AIC with mixed-effects models [@liang2008] we provide functionality to perform k-fold cross-validation.
The function `sdmTMB_cv()` allows for any number of folds, with assignments being user-specified or chosen randomly. 
The predictive log-density is calculated for each fold and summarized across folds for a total measure of the predictive accuracy of a model.

## Model evaluation

Validation of mixed-effects models is non-trivial (that REF). We provide three approaches to assist with model validation:

1. The `residuals()` method returns randomized quantile residuals (e.g., as in DHARMa REF).
These residuals are calculated as $\hat{y} - y$ where $\hat{y}$ is the sum of the fixed effect estimates and the random effect values that maximumize the likelihood conditional on the estimated fixed effects. 
These residuals have known statistical issues (REF) but are quick to calculate. One-step-ahead residuals (REF) or residuals from a single MCMC draw (REF) are also possible, but both approaches are much slower.

2. The `sdmTMB_simulate()` function can simulate new data, or simulate from a fitted model, to which models can be fit to ensure identifiability, evaluate bias and precision in parameter estimation, or evaluate the consequences of model misspecification.

3. An sdmTMB model can be passed to the tmbstan package [@monnahan2018] to sample from the joint posterior with Stan (REF) to evaluate the accuracy of the Laplace approximation (see `?extract_mcmc`). 
We note this will be considerably slower to fit than with maximum likelihood and in some cases may require tight priors or fixed parameters to ensure adequate sampling (REF).

## Parameter priors/penalties

sdmTMB models can include penalized likelihoods by assigning priors to model parameters (`?sdmTMBpriors`).
These priors may be useful in cases where estimation is difficult because of identifiability issues or relatively flat likelihood surfaces, or to impart prior information or achieve regularization.
Following other recent SPDE implementations [@simpson2017; @breivik2021; @osgood-zimmerman2021], penalized complexity ('PC') priors (`pc_matern()`) may be particularly useful to constrain the spatial range and variance parameters.

## Derived quantities of interest

The results from an sdmTMB model can be used to generate various quantities of interest.
For example, sdmTMB provides functionality for generating population-level summaries for each time slice including the center of gravity (`get_cog()`) and total population index (`get_index()`).
Estimated parameters from the Matérn covariance function can be used to describe the marginal spatial variance and Matérn range.

<!-- Paragraph on advanced options here?
Specifically, this could address
- PC-priors -- and other penalized priors
- Non-linear stuff / etc
- Linkages to Rstan
- Simulation
-->

<!-- ## Advanced options -->

<!-- While not of interest to all users, sdmTMB also implements several advanced options for model fitting.  -->
<!-- First, models can include penalized likelihoods via assigning priors to model parameters. -->
<!-- These priors may be useful in cases where estimation is difficult because of identifiability issues or relatively flat likelihood surfaces. -->
<!-- Following other recent SPDE approaches [@simpson2017; @osgood-zimmerman2021], 'penalized complexity' priors may be particularly useful in assigning priors to the spatial range and variance. -->
<!-- Second, we allow non-linear effects of covariates to be modeled with penalized regression splines ("P-splines") [@eilers1996], in one or multiple dimensions, using the same `s(x)` syntax familiar to users of `mgcv`. -->
<!-- Third, for users interested in Bayesian inference, we allow models to be passed to Stan (cite) via the package tmbstan [@monnahan2018]. -->

# An introductory example

An sdmTMB model requires a data frame that contains a response column, columns for any predictors, and columns for spatial coordinates.
It usually makes sense to convert the spatial coordinates to UTMs such that distance remains constant throughout the study region (e.g., using `sf::st_transform()`).
Here, we illustrate a spatial model fit to Pacific cod (*Gadus macrocephalus*) trawl survey data from Queen Charlotte Sound, BC, Canada.
Our model contains a main effect of depth as a penalized smoother, a spatial random field, and Tweedie observation error.
Our data frame `pcod` (built into the package) has a column `year` for the year of the survey, `density` for density of Pacific cod in a given survey tow, `depth` for depth in meters of that tow, and spatial coordinates `X` and `Y`, which are UTM coordinates in kilometers:

```{r, include=FALSE}
# simplify for paper
pcod <- dplyr::select(pcod, year, density, depth, X, Y)
```

```{r, echo=TRUE, eval=FALSE}
library(sdmTMB)
head(pcod)
```

```{}
#>    year density depth     X     Y
#>   <int>   <dbl> <dbl> <dbl> <dbl>
#> 1  2003   113.    201  446. 5793.
#> 2  2003    41.7   212  446. 5800.
#> 3  2003     0     220  449. 5802.
```

We start by creating a mesh object that contains matrices to apply the SPDE approach:

```{r, echo=TRUE}
mesh <- make_mesh(pcod, xy_cols = c("X", "Y"), cutoff = 10)
```

Here, `cutoff` defines the minimum allowed distance between points in the units of `X` and `Y` (km).
Alternatively, we could have created any mesh via the INLA package and supplied it to `make_mesh()`. 
We can inspect our mesh object with the associated plotting method (`plot(mesh)`; see Fig. \@ref(fig:pcod-fig)a).

We can then fit a model with spatial random fields via the function `sdmTMB()`. 
We use a penalized smoother for depth as a main effect via `s()` from the mgcv package.
We specify the family as Tweedie to account for positive continuous density values that also contain zeros.

```{r pcod-eg1-fit, warning=FALSE, message=FALSE, cache=TRUE, echo=TRUE}
fit <- sdmTMB(
  density ~ s(depth),
  data = pcod,
  family = tweedie(link = "log"),
  mesh = mesh,
  spatial = "on"
)
```

Setting `silent = FALSE` would indicate optimization progress, which is helpful for larger models.
We can get a summary of the fit with the `print()` method or extract parameter estimates as a data frame with the `tidy()` method (omitted for space):

```{r,eval=FALSE, echo=TRUE}
print(fit)
```

<!-- tidy(fit, conf.int = TRUE) -->
<!-- tidy(fit, effects = 'ran_pars', conf.int = TRUE) -->

```{}
#> Spatiotemporal model fit by ML ['sdmTMB']
#> Formula: density ~ s(depth)
#> Mesh: mesh
#> Data: pcod
#> Family: tweedie(link = 'log')
#>             coef.est coef.se
#> (Intercept)     2.37    0.21
#>
#> Dispersion parameter: 12.69
#> Tweedie p: 1.58
#> Matern range: 16.39
#> Spatial SD: 1.86
#> ML criterion at convergence: 6402.136
```

The output indicates our model was fit by maximum (marginal) likelihood (`'ML'`).
We also see the formula, mesh, fitted data, and family.
Next we see any estimated fixed effects, the Tweedie dispersion and power parameters, the Matérn range distance, the marginal spatial field standard deviation, and the negative log likelihood at convergence.
Internally, `s(depth)` creates random effect spline weights and so is not shown here.

We can make predictions with the `predict()` method; we will predict on new data with the `newdata` argument.
The data frame `qcs_grid` (included in the package data) is a grid that extends over the full survey domain and contains all predictors used in the model set at values for which we want to predict.
The output of `predict()` is a data frame containing overall estimates, estimates from the non-random-field components (intercept and depth), and estimates from the random field components.
We show a basic plot of the estimated spatial random field, predictions across a depth gradient, and predictions in space in Fig. \@ref(fig:pcod-fig)b--d.

```{r, echo=TRUE, eval=FALSE}
p <- predict(fit, newdata = qcs_grid)
```

```{r, echo=FALSE, eval=TRUE}
p <- predict(fit, newdata = subset(qcs_grid, year == 2003))
```

```{r, eval=FALSE}
p3 <- predict(fit, newdata = subset(qcs_grid, year == 2003), sims = 500L)
se <- apply(p3, 1, sd)
p$se <- se
g_pred_se <- ggplot(p, aes(X, Y, fill = se)) +
  geom_raster() +
  scale_fill_viridis_c(trans = "log10", option = "C") +
  coord_fixed() +
  labs(fill = "Predicted\ndensity (units)", x = "UTMs E (km)", y = "UTMs N (km)") +
  theme(legend.position = c(0.2, 0.2), legend.key.height = unit(10, "pt"))
```

```{r, warning=FALSE, message=FALSE}
library(sf)
# devtools::install_github("ropensci/rnaturalearthhires") # install if needed
map_data <- rnaturalearth::ne_countries(
  scale = "large",
  returnclass = "sf", country = "canada")
# Crop the polygon for plotting and efficiency:
# st_bbox(map_data) # find the rough coordinates
bc_coast <- suppressWarnings(suppressMessages(
  st_crop(map_data,
    c(xmin = -134, ymin = 46, xmax = -120, ymax = 57))))
utm_zone9 <- 3156
bc_coast_proj <- sf::st_transform(bc_coast, crs = utm_zone9)
# ggplot(bc_coast_proj) + geom_sf()
```

```{r}
g_pred <- ggplot(bc_coast_proj) +
  geom_sf(fill = NA, colour = "gray30", lwd = 0.3) +
  geom_raster(data = p, aes(x = X * 1000, y = Y * 1000, fill = exp(est))) +
  coord_sf(datum = st_crs(utm_zone9)) +
  scale_x_continuous(
    limits = c(230957.7 + 105000, 1157991 - 570000),
    labels = function(x) paste0(x / 1000)
  ) +
  scale_y_continuous(
    limits = c(5366427 + 270000, 6353456 - 513000),
    labels = function(x) paste0(x / 1000)
  ) +
  scale_fill_viridis_c(trans = "sqrt", option = "C") +
  # scale_fill_viridis_c(trans = "sqrt", option = "B", begin = 0.3) +
  labs(fill = "Predicted\ndensity (units)", x = "UTMs E (km)", y = "UTMs N (km)") +
  theme(
    # panel.background = element_rect(fill = "slategray1", colour= "white"),
    legend.position = c(0.2, 0.2), legend.key.height = unit(10, "pt")
  )
```

```{r, echo=FALSE}
blues <- RColorBrewer::brewer.pal(5, "Blues")
reds <- RColorBrewer::brewer.pal(5, "Reds")
g_mesh <- ggplot(pcod, aes(X, Y)) +
  inlabru::gg(mesh$mesh, edge.color = "grey60") +
  geom_point(alpha = 0.6, mapping = aes(size = density), colour = blues[4]) +
  theme_minimal() + coord_fixed() +
  labs(x = "UTMs E (km)", y = "UTMs N (km)") +
  scale_size_area(max_size = 10) +
  theme(legend.position = "none")
```

```{r}
nd <- data.frame(
  depth =
    seq(min(pcod$depth), max(pcod$depth), length.out = 300)
)
p_smooth <- predict(fit, newdata = nd, se_fit = TRUE, re_form = NA)
g_smooth <- ggplot(
  p_smooth,
  aes(depth, exp(est),
    ymin = exp(est - 1.96 * est_se),
    ymax = exp(est + 1.96 * est_se)
  )
) +
  geom_ribbon(fill = blues[2]) +
  geom_line(colour = blues[5], lwd = 1) +
  labs(x = "Depth (m)", y = "Density (units)") +
  xlim(min(pcod$depth), 300) +
  coord_fixed(expand = FALSE, ratio = 1.28)
```

```{r fit-pcod-st, warning=FALSE, message=FALSE, cache=TRUE, eval=FALSE, echo=FALSE}
fit2 <- sdmTMB(
  density ~ 0 + as.factor(year),
  family = tweedie(link = "log"), data = sdmTMB::pcod, mesh = mesh,
  time = "year", spatial = "on", spatiotemporal = "iid", silent = TRUE
)
p2 <- predict(fit2, newdata = qcs_grid, sims = 500L)
ind <- get_index_sims(p2)
```

```{r plot-ind, eval=FALSE}
g_ind <- ggplot(ind, aes(year, est, ymin = lwr, ymax = upr)) + 
  geom_ribbon(fill = blues[2]) +
  geom_line(colour = blues[5], lwd = 1) +
  ylim(0, max(ind$upr)) +
  coord_fixed(expand = FALSE, ratio = 0.3) +
  labs(x = "Year", y = "Biomass (units)")
```

(ref:pcod-fig-cap) Output from the Pacific cod spatial model example in Queen Charlotte Sound, BC, Canada.
(a) SPDE mesh (lines) combined with the trawl survey observations (points).
Finer meshes will be slower to fit but increase the accuracy of the SPDE approximation.
The circle area corresponds to density of Pacific Cod for individual trawls.
(b) Conditional effect of depth modelled as a penalized smoother.
The line represents the estimate and the ribbon indicates a 95\% confidence interval (+/- 2 SEs).
These predictions are made omitting the spatial random field.
(c) Spatial random field:
these values are shown in link (log) space and represent spatially correlated deviations that are not accounted for by the depth effect.
(d) Overall prediction: these estimates represent the combination of all fixed and random effects.

```{r pcod-fig, fig.cap="(ref:pcod-fig-cap)", fig.width=9, out.width="5.2in", fig.asp=1, fig.align='center'}
g_omega <- ggplot(bc_coast_proj) +
  geom_sf(fill = NA, colour = "gray30", lwd = 0.3) +
  geom_raster(data = p, aes(x = X * 1000, y = Y * 1000, fill = omega_s)) +
  coord_sf(datum = st_crs(utm_zone9)) +
  scale_x_continuous(
    limits = c(230957.7 + 105000, 1157991 - 570000),
    labels = function(x) paste0(x / 1000)
  ) +
  scale_y_continuous(
    limits = c(5366427 + 270000, 6353456 - 513000),
    labels = function(x) paste0(x / 1000)
  ) +
  # scale_fill_gradient2(high = reds[4], low = scales::muted("purple")) +
  scale_fill_gradient2(high = reds[4], low = blues[4]) +
  labs(fill = "Spatial random\nfield deviations", x = "UTMs E (km)", y = "UTMs N (km)") +
  theme(
    # panel.background = element_rect(fill = "slategray1", colour= "white"),
    legend.position = c(0.2, 0.2), legend.key.height = unit(10, "pt")
  )
cowplot::plot_grid(g_mesh, g_smooth, g_omega, g_pred, labels = "auto")
```

We could extend our model to a spatiotemporal one simply by supplying the year column name to the `time` argument and specifying how we want the spatiotemporal random fields to be structured.
Here we will turn off the spatial field and structure the spatiotemporal random fields as AR(1):

```{r, eval=FALSE, echo=TRUE}
fit_spatiotemporal <- sdmTMB(
  density ~ s(depth), family = tweedie(link = "log"), data = pcod, mesh = mesh,
  time = "year", spatial = "off", spatiotemporal = "ar1"
)
```

We could generate a standardized index from that fit with:

```{r, eval=FALSE, echo=TRUE}
p <- predict(fit_spatiotemporal, newdata = qcs_grid, return_tmb_object = TRUE)
ind <- get_index(p)
```

As a third example, we could model presence/absence of Pacific cod (`present`) with a time-varying quadratic effect of depth, an independent mean each year, a spatial random field, and IID spatiotemporal fields:

```{r, eval=TRUE, echo=FALSE}
# restore 'present' column
pcod <- sdmTMB::pcod
```

```{r, eval=FALSE, echo=TRUE}
fit_spatiotemporal_tv <- sdmTMB(
  present ~ 0 + as.factor(year), 
  time_varying = ~ 0 + poly(depth, 2), 
  family = binomial(), data = pcod, mesh = mesh,
  time = "year", spatial = "on", spatiotemporal = "iid"
)
```

<!--
Highlights?

- Basic spatial model structure and notation / INLA / SPDE / GMRF defined. Advantages of PC-priors [], though sdmTMB also allows priors on most parameters (e.g. fixed effects, obs error variances)
- Flexible extension of glmmTMB [Brooks et al. 2017] -- and includes non-spatial models for direct comparisons with glmmTMB [@osgood-zimmerman2021]
- Spatiotemporal models (RW/AR v IID)
- Time varying parameters
- Non-linear effects (smooth splines, threshold/breakpoint functions)
- Variance estimation and derived quantities (spatial range, area occupied etc)
-->

\clearpage 

```{r compare-table}
library(kableExtra)
suppressMessages(suppressWarnings(d <- readr::read_csv(here::here("doc/software-comparison.csv"), show_col_types = FALSE, comment = "#")))
d <- as.matrix(d)
d[d == "1"] <- "\\checkmark"
d[d == "1*"] <- "\\checkmark\\footnote{a}"
d[d == "0"] <- "--"
d[d == "0*"] <- "--\\footnote{a}"
d <- as.data.frame(d)
names(d)[1] <- ""
row.names(d) <- NULL
d <- d[,c(1, 2, 3, 5, 6, 4, 7, 8, 9)]
names(d)[names(d) == "mgcv"] <- "mgcv\\footnote{a}"

knitr::kable(d, format = "latex", caption = "Comparison of functionality between eight R packages that can fit geostatistical GLMMs.", 
  booktabs = TRUE, 
  linesep = c(
    rep('', 4), # coefs
    '\\addlinespace',
    rep('', 5), # correlation stuff
    '\\addlinespace',
    rep('', 11), # likelihood
    '\\addlinespace',
    rep('', 2), # bayes
    '\\addlinespace'
  ),
  escape = FALSE, row.names = FALSE) %>%
  kableExtra::kable_styling(font_size = 8) %>% 
  kableExtra::footnote(
    number = c(
      "SPDE approach as in Miller et al. (2019).",
      "Technically possible but non-trivial.",
      "Zero-inflated NB2 only.",
      "Tweedie power parameter fixed for \\\\texttt{mgcv::gamm()}.",
      "Technically possible but non-trivial.",
      "Technically possible but non-trivial."
    ),
    escape = FALSE
  )
```

# Speed comparison

We ran a simple speed comparison between sdmTMB, inlabru, and mgcv for fitting a SPDE spatial random field model to 1000 data points with Gaussian error across a range of mesh resolutions (Fig. \@ref(fig:timing)).
In this test, for mesh resolutions under 500 nodes, sdmTMB fit the models the fastest.
inlabru was the least affected by mesh resolution and beyond 500 nodes was faster than sdmTMB with default sdmTMB settings.
mgcv was slightly slower than sdmTMB and was more affected by mesh resolution.
With the random effect normalizing constant calculated in R (`normalize = TRUE`), sdmTMB was the fastest across all mesh resolutions (note that this option may not be possible or as fast for all models).
Results with up to an order of magnitude more data points slightly shift the lines up without affecting the overall pattern (not shown).

(ref:timing-fig) Comparison of time to fit an SPDE spatial random field model with 1000 observations, an intercept and one predictor, Gaussian error, and a sequence of SPDE resolutions.
Lines represent means and ribbons ranges across 20 random iterations.
Note the log x and y axes.
sdmTMB used the default settings and `normalize = TRUE`, which calculates the random effect normalizing constant in R.
inlabru used the empirical Bayes integration strategy and Gaussian approximation with `bru_max_iter = 1`, and the `like()` formulation.
mgcv used `bam()`, `method = fREML`, and discretized covariates [@miller2019].
inlabru/INLA could be faster with the PARDISO sparse linear solver and TMB could be faster with an optimized BLAS library.
All platforms were restricted to one core and could be faster with parallel computation.
<!-- https://www.sciencedirect.com/science/article/abs/pii/S0167739X00000765 -->


```{r timing, fig.cap="(ref:timing-fig)", out.width="3.5in", fig.align='center'}
f <- here::here("figs", "timing2-logx.pdf")
if (!file.exists(f)) {
  download.file("https://www.dropbox.com/s/3aco85mizuplz7z/timing2-logx.pdf?dl=1", 
    destfile = f)
}
knitr::include_graphics(f)
```

# Discussion

<!-- Take home, re-iterate paragraph? -->

There are many R packages available for fitting spatially explicit models to large datasets and we cannot review them all here [see @heaton2017]; however, the three most closely related are VAST, inlabru, and mgcv (Table 1). 
VAST is also built on TMB and, for univariate data, should be able to fit equivalent models with some minor differences in functionality.
The difference lies mainly in the user interfaces and considerable additional functionality for multivariate response data (REF) and delta/hurdle models (REF) in VAST.
Interface-wise, VAST is a less modular interface (e.g., by default automatically constructing meshes before fitting, making predictions at the same time as fitting), is written from a fisheries index standardization perspective (e.g., splitting 'catchability' and 'habitat' covariates), and lacks some interface elements that we think make sdmTMB more broadly usable by applied ecologists. 
For example, `sdmTMB()` has a `family` argument as in `glm()`, a `predict()` method, and human-readable options for spatial/spatiotemporal fields (e.g., `spatial = 'on'`, `spatiotemporal = 'AR1'`).
sdmTMB achieves three of the four design principles outlined in @thorson2019 for index standardization: it allows area weighting, can distinguish catchability and habitat covariates (by deciding what is fixed when predicting), and conditions on missing covariates (random fields).
Unlike VAST, however, sdmTMB does not currently extend to multivariate applications.

<!--         -   "VAST represents four main design principles. Although there are many other implementation details that distinguish VAST from previous index-standardization methods, I believe that these four design principles represent the features that any future replacement should include." -->
<!--         -   Area weighting (check, helper functions to sum up weighted grid cells) -->
<!--         -   Distinct catchability and habitat covariates (check, decide what goes into `predict()`) -->
<!--         -   Condition on missing covariates (check, random fields) -->
<!--         -   Bridge between univariate and multivariate applications (no! should we? -->
<!-- However, VAST can fit multivariate spatiotemporal models (REF) and Poisson-link delta model (REF), whereas sdmTMB cannot. -->

inlabru is similar to sdmTMB in design, but differs fundamentally in that fitting is achieved via INLA and approximate Bayesian computation.
For some models, TMB/sdmTMB can be considerably faster than INLA/inlabru, but those differences depend on the SPDE mesh, model, algebra libraries, and fitting algorithm settings [Fig. \@ref(fig:timing), @osgood-zimmerman2021].
One major capability included in sdmTMB but not INLA/inlabru is anisotropy.
Furthermore, we think the sdmTMB interface will be more familiar than inlabru to users of `glm()`, lme4, mgcv, or glmmTMB.
On the other hand, inlabru fits additional model classes including log Gaussian Cox processes and may be particularly usable to those already familiar with INLA.

mgcv can fit many similar models to sdmTMB either with various flavours of splines or even with the SPDE approximation to random fields [@miller2019]; however, there are some notable advantages of sdmTMB for the specific class of models discussed here.
First, the smoothers typically used with mgcv (e.g., thin plate splines), while capable of making equivalent predictions [@miller2019; @pedersen2019], do not offer the ecological interpretability of a spatially explicit random field model (spatial range and variance estimates).
Second, the implementation of the Tweedie distribution in mgcv requires the power parameter to be fixed in a mixed effects model.
Third, mgcv does not have built-in functionality to calculate derived values with uncertainty such as population indexes or center of gravity.
Despite these sdmTMB advantages for the models discussed here, mgcv is an immensely powerful modelling package that extends well beyond spatial random field models.

Spatially and spatiotemporally explicit data are increasingly collected in ecology and have the power to reveal new ecological processes (REF) and improve ecological management (REF).
These data present statistical challenges to modelling them effectively and efficiently; appropriate models such as GLMMs with random fields are often computationally intensive and challenging to implement, interpret, and evaluate.
We hope the development of user-friendly interfaces such as sdmTMB opens this useful class of models to a wider audience of users.

# Acknowledgements

# Conflict of Interest statement

# Author Contributions

# Supporting Information

<!--
All submissions with more than one author must include an Authors’ contributions statement. All persons listed as authors on a paper are expected to meet ALL of the following criteria for authorship:

substantial contributions to conception and design, or acquisition of data, or analysis and interpretation of data, or drafting the article or revising it critically for important intellectual content;
final approval of the version to be published;
agreement to be accountable for the aspects of the work that they conducted and ensuring that questions related to the accuracy or integrity of any part of their work are appropriately investigated and resolved.
Acquisition of funding, provision of facilities, or supervising the research group of authors without additional contribution are not usually sufficient justifications for authorship. The statement should include an explanation of the contribution of each author. We suggest the following format for the Authors’ contributions statement:

AB and CD conceived the ideas and designed methodology; CD and EF collected the data; EF and GH analysed the data; AB and CD led the writing of the manuscript. All authors contributed critically to the drafts and gave final approval for publication. -->

# Data Availability

<!--
To enable readers to locate archived data from papers, we require that authors list the database and the respective accession numbers or DOIs for all data from the manuscript that has been made publicly available. For example, “Data available from the Dryad Digital Repository http://dx.doi.org/10.5061/dryad.41qh7 (Kiere & Drummond 2016).” When a DOI is available for the data, the full data citation should also be given in the reference list (see below). For further information see our data archiving policy.
-->


<!--
# Tables

1. Comparison to related software?

- VAST
- INLA
- mgcv
- glmmTMB
- glmmfields?
- other stuff on CRAN, spBayes etc.

# Figures

1. Flow diagram of functions? Not needed?
1. Speed with various knots and/or spatial complexity in comparison to INLA + VAST + ...?
1. Example application 1 - SDM, show mesh(?) and/or raw data, show predictions and SD in space,
1. Example application 2 - population index with stitched survey?

Content:

-   outline the general need for this type of modelling

-   outline the need for this type of package to make the models accessible and rapid to iterate on

-   emphasize the niche carved out: a fast, flexible, easy-to-use, predictive-process univariate spatial or spatiotemporal GLMM, scales from maximum likelihood to penalized likelihood to full Bayesian inference

-   outline the philosophy and how the functions work together

    -   modular
    -   familiar (similar to glm, lme4, glmmTMB, mgcv, etc.)
    -   separate fitting and predicting
    -   avoid expensive calculations unless needed

-   table comparison to related packages

-   case studies

    -   an SDM with time-varying depth?
    -   an index calculation?
    -   stitching surveys?

-   how it achieves the steps Jim described [@thorson2019] in what a VAST-related package has to be able to do (and how VAST does it vs. how sdmTMB does it)
    -   "VAST represents four main design principles. Although there are many other implementation details that distinguish VAST from previous index-standardization methods, I believe that these four design principles represent the features that any future replacement should include."
    -   Area weighting (check, helper functions to sum up weighted grid cells)
    -   Distinct catchability and habitat covariates (check, decide what goes into `predict()`)
    -   Condition on missing covariates (check, random fields)
    -   Bridge between univariate and multivariate applications (no! should we?)

-   speed comparisons (INLA [inlabru?], VAST, mgcv, glmmTMB without predictive process?)

-   intended audience: ecology, but much broader too

-   self simulation testing --- appendix

-   package comparison fitting --- appendix

-->

\clearpage

# References

::: {#refs}
:::

```{=tex}
\clearpage
\beginsupplement
```


<!--

### Junk to delete
*EW: These are just placeholders -- not sure what order is best or what to highlight in very limited space*

As a first example, we use a spatial dataset (`parana`) from the `geoR` package (Ribeiro Jr and Diggle 2018) that describes average May-June rainfall recorded at 143 stations in the state of Paraná, Brazil. This dataset is also well-known because it is used as an example of spatiotemporal modeling with INLA (cite INLA) book. Because the dataset doesn't include covariates and only includes a single year, we can model rainfall using an intercept and spatial component, $g(\mu_{s,t}) = b_{0} + \omega_{s}$. We assume the observation model for the rainfall data is normally distributed. The first step in fitting a model with `sdmTMB` is constructing the mesh to approximate the spatial process. This step can be done with the `make_mesh` function, which accepts the data (coordinates) and at minimum, the minimum allowed distance between points (`cutoff`) or approximate number of knots in the mesh (`n_knots`). Custom built meshes with INLA can also be passed in (additional examples of this are included in the SI). For example, an initial mesh with a cutoff distance of 0.1km could be made with

```{r eval=FALSE, echo=TRUE}
rain_spde = make_mesh(data = parana, c("east","north"), cutoff=0.1)
```

Second, we can fit the model using TMB with the `sdmTMB` function, whose formula syntax should be familiar to most R users,

```{r eval = FALSE, echo=TRUE}
fit = sdmTMB(data ~ 1, data=parana, spde = rain_spde)
```

As a second example, we use `sdmTMB` to analyze a 2-year dataset of Eurasian cranes (*Grus grus*) from England, UK (Soriano-Redondo et al. 2019). In the original analysis, Soriano-Redondo et al. 2019 used log Gaussian Cox process models to jointly model crane presence--absence and the spatiotemporal distribution of wetlands. We use this dataset as an example of modeling presence--absence data with sdmTMB, and only model the occurence of cranes given covariates. With any multi-year dataset, a common question of interest is often whether observations can be best described by spatial variation, or spatial and spatiotemporal variation. With two years of data, we fit two models with `sdmTMB`: a model with a spatial component but no spatiotemporal variation, and a model with only spatiotemporal variation (allowing each year to have a different spatial field). We included the same fixed effect covariates in both models: different intercepts by year, and two covariates found to be important by Soriano-Redondo et al. 2019 (wetland area, perimeter to area ratio). As a coarse comparison of data support, we compare the Akaike's Information Criterion (Akaike 1973) from each model. The model with a shared spatial field appeared to be more supported ($\Delta AIC$=25.23). The sdmTMB package allows for additional model comparisons, including k-fold cross validation with the `sdmTMB_cv` function.

Third more detailed example -- something like `pcod` or a fisheries dataset, with the Tweedie distribution, use of predict() function, and creating indices of abundance?
-->
