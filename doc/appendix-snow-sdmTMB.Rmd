---
title: "Appendix 3: Example of a spatially varying effect of climate on citizen science count data with sdmTMB"
output:
  bookdown::pdf_document2:
    highlight: pygments
    toc: true
    number_sections: true
urlcolor: blue
bibliography: refs.bib
csl: mee.csl
---

```{r setup, include = FALSE, cache=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.asp = 1.5, 
  out.width="100%",
  cache = TRUE,
  autodep = TRUE,
  cache.comments = FALSE
)
```

# Background

This appendix illustrates the fitting of a model with a spatially varying coefficient for the effect a regional climate index on species count data using sdmTMB. 
We will use counts of Snowy Owls (*Bubo scandiacus*) observed in North America during annual Christmas Bird Counts [CBCs, @cbc]. 
Each survey is conducted between December 14 to January 5 in 24.14 kilometre diameter circle. 
Circle locations are chosen by local volunteers and therefore reflect both locations of higher human densities and known bird watching locations.
Each circle (given a unique ID) is generally surveyed annually by at least 10 volunteers, or deemed inactive. 
While these locations are not random, the consistent sampling through time still make them useful for exploring spatiotemporal processes. 

Snowy Owls (*Bubo scandiacus*) breed on the arctic tundra and are irruptive migrants, meaning that they appear across the mid latitudes of North America in much greater numbers in some winters than others.
The reasons for the interannual variation in the number of individuals migrating south are not well understood, but seem to be related to high abundances of food during the breeding season and therefore sharp increases in breeding ground population densities [@robillard2016]. 
The North Atlantic Oscillation Index (NAO) has been linked to productivity of both owls and their prey in Europe [@millon2014]. 
On average a positive NAO index results in colder and drier conditions in northern Canada and mild and wetter conditions in the eastern United States [@liu2021]. 
For this analysis, we have defined survey year as the year prior to/ending during the survey window. 
For these years, we have retrieved mean annual climate indices from the University of East Anglia's Climatic Research Unit <https://crudata.uea.ac.uk/cru/data/nao/>. 
Because both productivity and the choice of wintering location could be influenced by climate, we will test for a spatially variable effect of annual mean NAO index between 1979 and 2020 on winter owl abundance. 
Our model will span the southern boundary of their winter distribution in North America, the only portion of their range well surveyed by CBCs. 

# Preparation of spatial data

```{r packages, message=FALSE, warning=FALSE, cache=FALSE}
library(ggplot2)
library(patchwork)
library(dplyr)
# remotes::install_github("pbs-assess/sdmTMB", dependencies = FALSE)
library(sdmTMB)
library(sf)
```

```{r load-data, cache=FALSE} 
snow <- readRDS(here::here("data/SNOW_data.rds"))
glimpse(snow)
```

Here, X and Y are coordinates in Albers projection for North America and divided by 100000 to give units of 100 km. 
This projection was achieved with the following crs code using `sf::st_transform(crs = Albers)` [@pebesma2018]. 

```{r proj, echo=TRUE}
Albers <- "+proj=aea +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0
+datum=NAD83 +units=m +no_defs"
```

First, we construct a mesh to approximate the spatial process, which is used in the SPDE calculations. The `make_mesh()` function accepts the data coordinates and the minimum allowed distance between vertices (`cutoff`) or approximate number of knots in the mesh (`n_knots`). This mesh uses a cutoff distance of 1.5 units (or 150 km).

```{r mesh, echo=TRUE, cache=FALSE, out.width="80%"}
mesh <- make_mesh(snow, xy_cols = c("X", "Y"), cutoff = 1.5)
plot(mesh)
```

The result is a mesh with `r mesh$mesh$n` (`mesh$mesh$n`) knots. 

Next, we will plot the owl counts through time to see if there is an obvious overall trend, or relationship with NAO. The dataframe also contains the Southern Oscillation Index (SOI), which is related to El NiÃ±o cycles, but we will only consider NAO in this example because any effect of SOI was even weaker. 

```{r explore, fig.asp = 0.3, cache=FALSE}
ggplot(snow, aes(year, count, colour = nao)) +
  geom_jitter() +
  scale_colour_viridis_c() +
  theme_light()
```

# Model structure

First, we will try fitting GLMMs (generalized linear mixed effects models) with a few different distributions appropriate for count data. 
<!-- We will use `normalize = TRUE` to speed up optimization.  -->
<!-- Setting `silent = FALSE` would give us optimization details as the model fits but clutter the R Markdown output. -->
Our only fixed effect will be the NAO climate index (`nao`), but because of the wide spatial extent of these surveys, we also expect that the effect of NAO might not be consistent throughout North America. 
Therefore, the effect of NAO will also be allowed to vary spatially using this formula: `spatial_varying = ~ 0 + nao`.
Because there does not appear to be much correlation between years, year will be included as a random factor: `(1 | year_f)`. 
We will also include a fixed spatial random field (`spatial = "on"`) to account for consistent differences in habitat, proximity to the breeding grounds, and effects of flyways and barriers like coasts, and independent and identically distributed spatiotemporal random field (`spatiotemporal = "iid"`) to allow for annual deviations in these spatial effects due to factors like local weather and prey abundance. 
The random intercept for year allows the mean estimate for each of these spatiotemporal fields to vary. 
If years in sequence were strongly correlated with each other, we could use a random walk to link their mean estimates by setting `time_varying = ~ 1`.
It might also be appropriate to include count ID as another random effect `(1 | CBCID)` to account for consistent differences between count circles in habitat and human observers. 
But since its inclusion doesn't change our main result and it slows model fitting, we will rely on the spatial random effects to link observations in the same location for this example. 


Since these models will take a while to fit, in practice, we might set `silent = FALSE` to monitor optimization progress. 
However, we will maintain the default `silent = TRUE` to avoid cluttering the document with the output.

```{r rds1, echo=FALSE, cache=FALSE}
rds_saved <- file.exists(here::here("data/snow_w_main_effect_0_150km.rds"))
```

```{r fit-poisson, echo=TRUE, eval=!rds_saved, warning=FALSE}
m0 <- sdmTMB(count ~ 1 + nao + (1 | year_f),
  spatial_varying = ~ 0 + nao,
  time = "year",
  spatial = "on",
  spatiotemporal = "IID",
  family = poisson(link = "log"),
  data = snow, mesh = mesh,
  silent = TRUE
)
```

```{r fit-negb1, echo=TRUE, eval=!rds_saved, warning=FALSE}
m1 <- sdmTMB(count ~ 1 + nao + (1 | year_f),
  spatial_varying = ~ 0 + nao,
  time = "year",
  spatial = "on",
  spatiotemporal = "IID",
  family = nbinom1(link = "log"),
  data = snow, mesh = mesh,
  silent = TRUE
)
```

```{r fit-negb2, echo=TRUE, eval=!rds_saved, warning=FALSE}
m2 <- sdmTMB(count ~ 1 + nao + (1 | year_f),
  spatial_varying = ~ 0 + nao,
  time = "year",
  spatial = "on",
  spatiotemporal = "IID",
  family = nbinom2(link = "log"),
  data = snow, mesh = mesh,
  silent = TRUE
)
```


# Model validation

## Basic inspection
```{r save-models, warning=FALSE, message=FALSE, echo=FALSE, cache=FALSE, eval=TRUE}
if (!rds_saved) {
  saveRDS(m0, here::here("data/snow_w_main_effect_0_150km.rds"))
  saveRDS(m1, here::here("data/snow_w_main_effect_1_150km.rds"))
  saveRDS(m2, here::here("data/snow_w_main_effect_150km.rds"))
}
```

```{r load-models, warning=FALSE, message=FALSE, echo=FALSE, cache=FALSE}
if (rds_saved) {
  m0 <- readRDS(here::here("data/snow_w_main_effect_0_150km.rds"))
  m1 <- readRDS(here::here("data/snow_w_main_effect_1_150km.rds"))
  m2 <- readRDS(here::here("data/snow_w_main_effect_150km.rds"))
}
```

```{r aic, echo=TRUE, cache=FALSE}
AIC(m0, m1, m2)
```

According to AIC, the `nbinom2()` (negative binomial, NB2) distribution appears to have the most parsimonious fit. 
We will rerun with `reml = TRUE` to ensure better estimation of the random effects that dominate this model and check that the gradients are all small enough.
If the gradients aren't quite small enough, we can easily run additional optimization steps using the `run_extra_optimization()` function.

```{r rds2, echo=FALSE, cache=FALSE}
rds_saved2 <- file.exists(here::here("data/snow_w_main_effect_150km_reml.rds"))
```

```{r fit-negb2-reml, echo=TRUE, eval=!rds_saved2, warning=FALSE, cache=FALSE}
m <- sdmTMB(count ~ 1 + nao + (1 | year_f),
  spatial_varying = ~ 0 + nao,
  time = "year", 
  spatial = "on", 
  spatiotemporal = "iid",
  family = nbinom2(link = "log"),
  reml = TRUE,
  data = snow, mesh = mesh,
  silent = TRUE
)

if (max(m$gradients) > 0.01) {
  m <- run_extra_optimization(m, newton_loops = 1L, nlminb_loops = 0L)
}
```

```{r save-reml-model, warning=FALSE, message=FALSE, echo=FALSE, cache=FALSE, eval=FALSE}
if (!rds_saved2) {
  saveRDS(m, here::here("data/snow_w_main_effect_150km_reml.rds"))
}
```

Print the model to inspect the fit:

```{r check, echo=FALSE, include=FALSE, eval=TRUE, cache=FALSE}
if (rds_saved2) {
  m <- readRDS(here::here("data/snow_w_main_effect_150km_reml.rds"))
  m # printing this first just prevents some excess messages from cluttering the output when printing below
}
```

```{r print-fit, warning=FALSE, echo=TRUE, message=FALSE, cache=FALSE}
print(m)
```

View the confidence intervals on both fixed and random (and variance) parameter estimates using `tidy()`.

```{r tidy, cache=FALSE}
tidy(m, conf.int = TRUE)
tidy(m, effects = "ran_pars", conf.int = TRUE)
```

We can then generate predictions and residuals for the original data locations:

```{r predict, message=FALSE}
pred <- predict(m)
pred$resid <- residuals(m)
```

<!-- \clearpage -->

## Checking residuals

We can inspect randomized quantile residuals, although this method has known issues. 

```{r qqnorm, fig.asp = 1, out.width="33%", cache=FALSE}
qqnorm(pred$resid)
qqline(pred$resid)
```

More accurate residuals can be generated using tmbstan, but this is a very slow process!
In this case, it took more than 2.5 hrs.

```{r stan-resids, eval=FALSE}
stan_fit <- tmbstan::tmbstan(m$tmb_obj, iter = 100, chains = 1, warmup = 99)
eta <- predict(m, tmbstan_model = stan_fit)
mu <- m$family$linkinv(as.numeric(eta))
r_mcmc <- sdmTMB:::qres_nbinom2(m, y = m$data$count, mu = mu)
saveRDS(r_mcmc, "data/mcmc_residuals.rds")
```

```{r stan-dat, echo=FALSE, cache=FALSE}
r_mcmc <- readRDS(here::here("data/mcmc_residuals.rds"))
```

```{r stan-qqnorm, fig.asp = 1, out.width="33%", cache=FALSE}
qqnorm(r_mcmc)
qqline(r_mcmc)
```

We can also test for zero-inflation using the `simulate.sdmTMB` function and a couple functions from the DHARMa package.
If our data were zero-inflated or overdispersed, we might have needed to use a delta ("hurdle") model instead. 
This is not built directly into sdmTMB, but can be achieved by fitting the two components separately. See the steps in the vignette [Fitting delta models with sdmTMB](https://pbs-assess.github.io/sdmTMB/articles/delta-models.html).

```{r zero-test, echo=TRUE, message=FALSE}
s_nb2 <- simulate(m, nsim = 500)
pred_fixed <- m$family$linkinv(predict(m)$est_non_rf)
r_nb2 <- DHARMa::createDHARMa(
  simulatedResponse = s_nb2,
  observedResponse = m$data$count,
  fittedPredictedResponse = pred_fixed
)
DHARMa::testZeroInflation(r_nb2, plot = FALSE)
```

Next, we modify a theme to plot spatiotemporal data and check the distribution of these residuals:

```{r theme, cache=FALSE}
theme_set(theme_bw() + theme(
  plot.title = element_text(size = 12),
  legend.position = "top", legend.justification = c(0, 0), # move legend to top left
  legend.title = element_text(size = 10, hjust = 0), legend.key.height = unit(0.3, "cm"),
  strip.background = element_rect(fill = NA, colour = NA), # de-emphasize facet labels
  panel.grid.major = element_line(colour = "grey90"), # for lat/lons
  axis.title = element_blank() # lat/lon is clear from axis text
)) 
```

```{r plot-resids, fig.width=8}
ggplot(pred, aes(X, Y, colour = resid)) +
  geom_point(size = 0.25) +
  facet_wrap(~year) +
  coord_fixed() +
  scale_colour_gradient2(guide = guide_colourbar(title.position = "top")) +
  theme(axis.text = element_blank(), axis.ticks = element_blank())
```

<!-- ## Cross-validation -->

<!-- Cross-validation can also be used to assess model performance. -->
<!-- Here, we use the `future` package to speed up the running of multiple models and save a smaller version of the output that doesn't include the full model information. -->
<!-- We use `k_folds = 5`, which amounts to training on 80% of the data and testing with 20% for each model. -->
<!-- Block cross-validation, which can be done using custom folds defined using the `fold_ids` argument, is generally recommended for spatiotemporal data. -->
<!-- However, random folds created by `sdmTMB_cv()` are appropriate in this case, because we are only interested in predicting within the spatial and temporal range of our data and are attempting to estimate the spatial variation in the effect of NAO. -->

<!-- ```{r cv, eval=FALSE, cache=FALSE} -->
<!-- library(future) -->
<!-- plan(multisession) -->
<!-- options(future.rng.onMisuse = "ignore") -->

<!-- m_cv <- sdmTMB_cv(count ~ 1 + nao + (1 | year_f), -->
<!--   spatial_varying = ~ 0 + nao, -->
<!--   time = "year", -->
<!--   spatial = "on", -->
<!--   spatiotemporal = "iid", -->
<!--   family = nbinom2(link = "log"), -->
<!--   reml = TRUE, -->
<!--   use_initial_fit = TRUE, -->
<!--   data = snow, mesh = mesh, -->
<!--   k_folds = 5 -->
<!-- ) -->
<!-- plan(sequential) -->
<!-- saveRDS(m_cv, file = here::here("data/owlcvallreml.rds")) -->
<!-- # m_cv$models[[1]] # to retrieve just the model built excluding the first fold -->
<!-- cv <- m_cv -->
<!-- cv$models <- NA -->
<!-- saveRDS(cv, file = here::here("data/owlcvdatreml.rds")) -->
<!-- ``` -->

<!-- First, we should check that all the models converged and have gradients < 0.01. -->

<!-- ```{r explore-cv, message=FALSE, cache=FALSE} -->
<!-- cv <- readRDS(here::here("data/owlcvdatreml.rds")) -->
<!-- cv$converged -->
<!-- max(cv$max_gradients) -->
<!-- ``` -->

<!-- If we were conducting model selection, we might contrast the log likelihoods (`cv$sum_loglik`), and the expected log predictive density (`cv$elpd`) for the left out data between different model configurations instead of relying on AIC. -->
<!-- We can also check the prediction accuracy on left-out data by plotting the `cv_predicted` against the observed `count` in log space. -->

<!-- ```{r cv-pred-obs, out.width="70%", cache=FALSE} -->
<!-- cvdat <- cv$data %>% filter(cv_loglik > -60) # this removes one extreme outlier -->
<!-- ggplot(cvdat, aes(log(count + 1), log(cv_predicted + 1), colour = -cv_loglik)) + -->
<!--   geom_abline(slope = 1, colour = "gray") + -->
<!--   geom_point(size = 2, alpha = 0.25) + -->
<!--   scale_colour_viridis_c( -->
<!--     direction = -1, option = "A", begin = 0.2, end = 0.9 -->
<!--   ) + -->
<!--   coord_fixed(ylim = c(0, 3.8)) + -->
<!--   theme_bw() -->
<!-- ``` -->

<!-- These predictions for left-out locations match the observed counts just as well as those based on the model built using all the data shown below. -->
<!-- # Does this mean that we are at least not over-fit, despite the spatiotemporal random fields and spatially varying coefficient? -->

<!-- ```{r full-pred-obs, echo=FALSE, out.width="70%"} -->
<!-- ggplot(pred, aes(log(count + 1), log(exp(est) + 1), colour = resid)) + -->
<!--   geom_abline(slope = 1, colour = "gray") + -->
<!--   # geom_point(size = 0.75, alpha=0.5) + facet_wrap(~year) + -->
<!--   geom_point(size = 2, alpha = 0.25) + -->
<!--   coord_fixed(ylim = c(0, 3.8)) + -->
<!--   scale_colour_viridis_c( -->
<!--     "residuals", -->
<!--     direction = -1, option = "A", begin = 0.2, end = 0.9 -->
<!--   ) + -->
<!--   theme_bw() #+ theme(strip.background = element_rect(fill = NA, colour = NA)) -->
<!-- ``` -->

<!-- We can also explore the spatiotemporal variation in the predictive accuracy of our model by plotting the `cv_loglik`. -->

<!-- ```{r cv-map, cache = FALSE} -->
<!-- ggplot(cvdat, aes(X, Y, colour = -cv_loglik)) + -->
<!--   geom_point(size = 0.25) + -->
<!--   scale_colour_viridis_c( -->
<!--     direction = -1, option = "A", begin = 0.2, end = 0.9, -->
<!--     guide = guide_colourbar(title.position = "top") -->
<!--   ) + -->
<!--   coord_fixed() + -->
<!--   theme(axis.text = element_blank(), axis.ticks = element_blank()) + -->
<!--   facet_wrap(~year) -->
<!-- ``` -->

<!-- \clearpage -->

# Plotting spatial predictions

To produce pretty maps of these predictions, we back transformed the spatial coordinates into the same units as our original projection and then convert back into an sf object so that the plot axis will be in latitude and longitude. 

```{r proj-p}
p <- pred %>% mutate(X = X * 100000, Y = Y * 100000)
p_proj <- p %>% mutate(x = X, y = Y) %>%
  sf::st_as_sf(coords = c("x", "y"), crs = Albers)
```

We retrieved continental coastlines from the package rnaturalearth and outlines of the great lakes from <http://www.naturalearthdata.com/> and transformed them to the correct projection.

```{r shapes}
if (!file.exists(here::here("data/ne_10m_lakes"))) {
  zip_file <- paste0("https://www.naturalearthdata.com/http//www.naturalearthdata.com/",
    "download/10m/physical/ne_10m_lakes.zip")
  download.file(zip_file, destfile = here::here("data/ne_10m_lakes.zip"))
  unzip(here::here("data/ne_10m_lakes.zip"), exdir = here::here("data/ne_10m_lakes"))
}
coast <- rnaturalearth::ne_coastline(scale = "medium", returnclass = "sf") %>%
  sf::st_transform(crs = Albers)
lakes <- sf::st_read(here::here("data/ne_10m_lakes"), quiet = TRUE)
lakes <- lakes[lakes$scalerank == 0, ] %>% sf::st_transform(crs = Albers)# only large lakes
```

## Spatially varying effect

We can then compress the annual predictions into mean values for plotting the spatially varying effect of NAO.
Most simply, we can extract the overall coefficients using the `b <- tidy(m)` and add them together with the spatially varying coefficients `zeta_s`.
However, this method does not give us spatially explicit estimates of uncertainty.
To do this, we can get the output from the joint precision matrix simulation draws by using the `predict()` function again, but this time indicating a number of simulation draws (e.g., `sims = 500`) and what component we want estimated (`sims_var = "zeta_s"`). 
We also extract the same number of draws for estimates of the main effect of NAO using the `spread_sims()` function (this time `n_sims = 500`). 
The simulation draws for both can then be combined before calculating the median and lower and upper quantiles from these draws (in this case we will use 80%) and adding these values to our prediction data frame.


```{r p-mean, message=FALSE, echo=TRUE, eval=TRUE}
b <- tidy(m, conf.int = TRUE)

n_sims <- 500L
zeta_sim <- predict(m, sims = n_sims, sims_var = "zeta_s")
sims <- spread_sims(m, n_sims = n_sims)
beta <- sims$nao
combined <- beta + t(zeta_sim)

p$zeta_sim <- apply(t(zeta_sim), 2, median)
p$nao_effect_sim <- apply(combined, 2, median)
p$nao_effect_lwr <- apply(combined, 2, quantile, probs = 0.10)
p$nao_effect_upr <- apply(combined, 2, quantile, probs = 0.90)

p_mean <- p %>%
  group_by(CBCID) %>% summarise(
    year = max(year),
    X = mean(X), Y = mean(Y),
    mean_est_count = exp(mean(est)),
    nao_effect = b[b$term == "nao", 2] + mean(zeta_s),
    nao_sim = mean(nao_effect_sim),
    nao_lwr = mean(nao_effect_lwr),
    nao_upr = mean(nao_effect_upr)
  )
```

```{r}
nao_effect_lwr95 <- apply(combined, 2, quantile, probs = 0.025)
```

The main effect of NAO indicates that there is a weak average positive effect of annual mean NAO on overall counts `r round(b[b$term == "nao", 2], 2)` (`b[b$term == "nao", 2]`), while for individual count locations the median estimated effects of NAO range from `r round(min(p_mean$nao_sim), 2)` to `r round(max(p_mean$nao_sim),2)` (`range(p_mean$nao_sim)`).
Based on the 80% CI calculated above, the resulting minimum estimated effects of NAO for each count location range from `r round(min(p_mean$nao_lwr), 2)` to `r round(max(p_mean$nao_lwr),2)` (`range(p_mean$nao_lwr)`) and the maximums range from `r round(min(p_mean$nao_upr), 2)` to `r round(max(p_mean$nao_upr),2)` (`range(p_mean$nao_upr)`). 
All these effects are in link space (`link = "log"`) and could be `exp()` to give the expected multiplicative contribution to the predicted owl counts, however the additive nature of the effect in link space is actually somewhat more intuitive to interpret visually, so this is what we will plot on our maps:


```{r plot-map, echo=TRUE, eval=TRUE, out.width="95%", cache=FALSE}
ggplot(data = p_proj) +
  geom_point(
    data = p_mean, aes(X, Y, colour = nao_effect, size = mean_est_count), alpha = 0.5
  ) +
  geom_sf(data = coast, colour = "gray50") +
  geom_sf(data = lakes, colour = "gray50", fill = NA) +
  coord_sf(
    xlim = c(min(p_proj$X) - 50000, max(p_proj$X) - 50000), # adjusts space on sides
    ylim = c(min(p_proj$Y), max(p_proj$Y))
  ) +
  scale_colour_viridis_c(
    limit = c(min(p_mean$nao_lwr), max(p_mean$nao_upr)), 
    guide = guide_colourbar(direction = "horizontal", title.position = "top")
  ) +
  guides(size = "none") +
  labs(colour = "Estimated effect in log space") +
  ggtitle("Map of combined main and spatially varying effects of NAO on Snowy Owl count") +
  theme(legend.position = c(0.1, 0.07), axis.title = element_blank())
```

```{r plot-map-ci, echo=F, eval=TRUE, out.width="100%", cache=FALSE}
p1 <- ggplot(data = p_proj) +
  geom_point(
    data = p_mean,
    aes(X, Y, colour = nao_lwr, size = mean_est_count), alpha = 0.5
  ) +
  geom_sf(data = coast, colour = "gray50") +
  geom_sf(data = lakes, colour = "gray50", fill = NA) +
  coord_sf(
    xlim = c(min(p_proj$X) - 50000, max(p_proj$X) - 50000), # adjusts space on sides
    ylim = c(min(p_proj$Y), max(p_proj$Y))
  ) +
  scale_colour_viridis_c(
    limit = c(min(p_mean$nao_lwr), max(p_mean$nao_upr)), 
    guide = guide_colourbar(direction = "horizontal", title.position = "top")
  ) +
  guides(size = "none", colour = "none") +
  # labs(colour = "Lower 90% CI") +
  ggtitle("Lower 80% CI") +
  theme(legend.position = c(0.1, 0.1), axis.title = element_blank())

p2 <- ggplot(data = p_proj) +
  geom_point(
    data = p_mean,
    aes(X, Y, colour = nao_upr, size = mean_est_count), alpha = 0.5
  ) +
  geom_sf(data = coast, colour = "gray50") +
  geom_sf(data = lakes, colour = "gray50", fill = NA) +
  coord_sf(
    xlim = c(min(p_proj$X) - 50000, max(p_proj$X) - 50000), # adjusts space on sides
    ylim = c(min(p_proj$Y), max(p_proj$Y))
  ) +
  scale_colour_viridis_c(
    limit = c(min(p_mean$nao_lwr), max(p_mean$nao_upr)), 
    guide = guide_colourbar(direction = "horizontal", title.position = "top")
  ) +
  guides(size = "none", colour = "none") +
  # labs(colour = "Upper 90% CI") +
  ggtitle("Upper 80% CI") +
  theme(legend.position = c(0.1, 0.1), axis.title = element_blank())

p1 + p2 + patchwork::plot_layout()
```

If we recalculated these at 95% CI the range of minimum estimates would be from `r round(min(nao_effect_lwr95), 2)` to `r round(max(nao_effect_lwr95),2)` meaning that for the most conventional level of statistical confidence, we cannot conclude that the effect of NAO at an annual scale differs from 0. 
However, the southeast to northwest gradient in the intensity illustrated in the maps above is consistent with owls closest to the Atlantic coast and those migrating the furthest south being the most affected by NAO.
This result suggests that exploring the effects of NAO at finer temporal scales (possibly seasonally) and/or with lagged effects could prove fruitful. 

<!-- \clearpage -->

## Predicted counts

These are the predictions of winter owl counts that incorporate all fixed effects and random effects. 
The mean estimated count is `r round(mean(exp(p$est)), 2)`, which is essentially equal to the observed mean of `r round(mean(snow$count), 2)`.
The maximum estimated count was `r round(max(exp(p$est)))`, but the colour axis on this plot has been transformed and trimmed to improve the visibility of variation in the lower range of count estimates. 

```{r plot-all-effects, echo=TRUE, eval=TRUE, cache=FALSE, cache=FALSE, out.width="95%"}
ggplot(data = p_proj) +
  geom_point(data = p, aes(X, Y, colour = exp(est)), size = 0.4, alpha = 0.5) +
  coord_sf(
    xlim = c(min(p_proj$X) - 50000, max(p_proj$X) - 50000),
    ylim = c(min(p_proj$Y), max(p_proj$Y))
  ) +
  scale_colour_viridis_c(
    trans = "sqrt", # makes variation in low numbers visible
    # can also trim the extreme high values
    limits = c(0, quantile(exp(p$est), 0.995)), na.value = "yellow",
    guide = guide_colourbar(title.position = "top")
  ) +
  labs(colour = "Predicted counts") +
  theme(axis.text = element_blank(), axis.ticks = element_blank()) +
  facet_wrap(~year_f)
```

<!-- Note that for all of these annually varying predictions, we are showing only the most recent 25 years.  -->

\clearpage
## Other components of predictions

In addition to the spatially varying effect that we started with, there are three other components that go into the overall predictions that we can plot spatially. 

### 1. Static spatial random effects 

We can look at the spatial random effects (`omega_s`) that represent consistent deviations in space that are not accounted for by our fixed effects. 
In other words, these deviations represent consistent biotic and abiotic factors that are affecting winter owl counts.
These could be landcover, proximity to the breeding grounds, and effects of flyways and barriers such as coasts.

```{r plot-spatial-effects, echo=TRUE, eval=TRUE, cache=FALSE, out.width="95%"}
ggplot(data = p_proj) +
  geom_point(data = p, aes(X, Y, colour = omega_s), alpha = 0.5) +
  geom_sf(data = coast, colour = "gray50") +
  geom_sf(data = lakes, colour = "gray50", fill = NA) +
  coord_sf(
    xlim = c(min(p_proj$X) - 50000, max(p_proj$X) - 50000),
    ylim = c(min(p_proj$Y), max(p_proj$Y))
  ) +
  scale_colour_viridis_c(guide = guide_colourbar(
    direction = "horizontal", title.position = "top"
  )) +
  theme(legend.position = c(0.1, 0.1), axis.title = element_blank())
```

\clearpage

### 2. Spatiotemporal random effects 

Finally, we can look at the spatiotemporal random effects (`epsilon_st`) that represent deviations from the fixed effect predictions and the spatial random effect deviations. 
These represent biotic and abiotic factors causing spatial correlation that are changing through time and are not accounted for in the model. 
For owls, this is most likely to be things like landcover changes, prey abundance cycles, and snow depth.

```{r plot-spatiotemporal-effects, echo=TRUE, eval=TRUE, cache=FALSE, out.width="95%"}
ggplot(data = filter(p_proj, year > 1978)) +
  geom_point(
    data = filter(p, year > 1978), aes(X, Y, colour = epsilon_st),
    size = 0.4, alpha = 0.5
  ) +
  coord_sf(
    xlim = c(min(p_proj$X) - 50000, max(p_proj$X) - 50000),
    ylim = c(min(p_proj$Y), max(p_proj$Y))
  ) +
  scale_colour_viridis_c(guide = guide_colourbar(title.position = "top")) +
  theme(axis.text = element_blank(), axis.ticks = element_blank()) +
  facet_wrap(~year_f)
```

<!-- Note that for these annually varying predictions, we are showing only the most recent 25 years.  -->

\clearpage

### 3. Just fixed effects

In this case, these only include the overall effect of mean annual NAO and the random intercepts for year.

```{r plot-fixed-effects, echo=TRUE, eval=TRUE, cache=FALSE, fig.asp = 1.5, out.width="100%"}
ggplot(data = filter(p_proj, year > 1978)) +
  geom_point(
    data = filter(p, year > 1978), aes(X, Y, colour = exp(est_non_rf)),
    size = 0.4, alpha = 0.5
  ) +
  coord_sf(
    xlim = c(min(p_proj$X) - 50000, max(p_proj$X) - 50000),
    ylim = c(min(p_proj$Y), max(p_proj$Y))
  ) +
  scale_colour_viridis_c(
    breaks = c(0.03, 0.05, 0.07),
    guide = guide_colourbar(title.position = "top")
  ) +
  theme(axis.text = element_blank(), axis.ticks = element_blank()) +
  facet_wrap(~year_f)
```

\clearpage
# References

::: {#refs}
:::
